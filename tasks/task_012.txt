# Task ID: 12
# Title: Implement Pagination Handling
# Status: pending
# Dependencies: 4, 5, 6, 7, 8, 9, 10
# Priority: medium
# Description: Enhance the ESPN API source to handle pagination for endpoints that return large datasets.
# Details:
Implement a generic pagination handler for ESPN API endpoints that support pagination:

```python
def paginated_request(url, params=None, limit=None):
    """Make paginated API requests"""
    if params is None:
        params = {}
    
    all_results = []
    page = 1
    more_pages = True
    
    while more_pages:
        # Add pagination parameters
        page_params = params.copy()
        page_params['page'] = page
        
        # Make the request
        response_data = make_api_request(url, page_params)
        
        # Extract results (adjust based on actual API response structure)
        page_results = response_data.get('items', [])
        all_results.extend(page_results)
        
        # Check if there are more pages
        more_pages = response_data.get('hasMore', False)
        
        # Increment page counter
        page += 1
        
        # Check if we've reached the optional limit
        if limit and len(all_results) >= limit:
            all_results = all_results[:limit]
            break
    
    return all_results
```

Then update relevant resource functions to use this pagination handler for endpoints that might return large datasets. For example:

```python
@dlt.resource(
    primary_key=["id"],
    write_disposition="merge"
)
def teams(limit=None):
    """Fetch team information with pagination support"""
    return paginated_request(f"{base_url}/teams", limit=limit)
```

Note: The actual pagination mechanism might differ based on the ESPN API's implementation. Adjust the `paginated_request` function accordingly after exploring the API's pagination behavior.

# Test Strategy:
Test the pagination handler with mock API responses that simulate multiple pages of data. Verify that it correctly fetches and combines all pages of data.
